---
title: "Moltbot REX: Setting Up a Local AI Assistant"
date: 2026-01-27
description: Masterize your privacy by running Moltbot locally
img: moltbot.png
figCaption: ""
tags: [AI, Moltbot, Agentic]
---

## Introduction to Moltbot
Moltbot is a cutting-edge **agent AI** designed to serve as your **personal assistant**, integrating seamlessly into your daily life. Unlike generic chatbots or AI tools, Moltbot is built to be **highly customizable, multi-platform, and locally controlled**, making it the ultimate choice for users who prioritize **privacy, security, and autonomy**.

### Key Features of Moltbot
1. **Multi-Platform Accessibility**
   - Reach your assistant from anywhere via **WhatsApp, Telegram, Discord, iMessage, Slack, and more**.
   - A single interface to manage all your tasks, communications, and automation across platforms.

2. **Seamless Integration with AI Providers**
   - Connects to multiple AI models (e.g., Anthropic, OpenAI, Google, Ollama...) via local or cloud endpoints.
   - Supports both **open-source and proprietary models**, ensuring flexibility and control over your AI interactions.

3. **Web Navigation and Automation**
   - Use built-in browser automation (via Chromium) to:
     - Scrape data from websites.
     - Fill forms, log in, and interact with web apps.
     - Schedule tasks or send messages programmatically.

4. **Persistent Memory System**
   - Unlike most AI tools that rely on short-term memory, Moltbot has a **long-term memory system** stored locally.
   - This means it can:
     - Recall past conversations, decisions, and preferences.
     - Track progress across sessions (e.g., follow-up tasks, reminders).
     - Adapt its behavior based on historical data.

5. **Full Local Control**
   - Runs entirely on your **personal hardware**, ensuring **no data leaks or third-party access**.
   - No reliance on cloud providers—your data stays private and under your control.

6. **Extensible with Skills**
   - Supports a wide range of **skills** (e.g., GitHub integration, Slack automation, weather updates) to extend functionality.
   - Easily add or remove skills based on your needs.

---

## Setting Up Moltbot Locally

### Why Go Local?
To ensure **full privacy and control**, I decided to host Moltbot entirely on my personal hardware. This means:
- **No data leaks**: All interactions, configurations, and memory are stored locally.
- **No dependency on cloud providers**: No risk of rate limits, downtime, or unexpected changes in AI model behavior.
- **Full customization**: I can tweak the AI models, browser automation, and system settings to fit my exact needs.

---

## Step-by-Step Setup

### 1. Environment Preparation
**Prerequisites:**
- A **Ubuntu Server 24.04** VM (or bare-metal machine).
- Sufficient hardware resources:
  - CPU: 2 cores.
  - RAM: At least 4GB.
  - Storage: At lease 20GB.
 
Test hardware I used for experiments:

- **Mac Mini M4** with **24GB RAM** running an **Ubuntu Server 24.04** guest inside a UTM VM. I host `Ministral 8B Thinking` with a 32K-token context window (the model configuration requires roughly **8GB of VRAM** for inference). I run LMStudio locally as my model host, but you can also use Ollama or any local provider that implements the OpenAI-compatible API — Moltbot only needs an OpenAI-style endpoint to work.

**Installation Steps:**
1. **Set up the VM:**
   For this, you can use your favorite virtual machine software like QEMU, VMWare, Proxmox, UTM... I will not explain how to install a Ubuntu Server, there is plenty of tutorial on the web to help you with this.
2. **Install Homebrew** (for package management):
   ```bash
   /bin/bash -c "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)"
   echo 'export PATH="/usr/local/bin:$PATH"' >> ~/.bashrc
   source ~/.bashrc
   ```
3. **Install Moltbot:**
   ```bash
   curl -fsSL https://molt.bot/install.sh | bash
   ```
   Follow the [official installation guide](https://molt.bot/docs/installation) for additional configurations.

---

### 2. Configuring AI Models
Moltbot supports multiple AI models, but I chose to use **Mistral** due to its performance and open-source nature.

**Installing LMStudio (Local Model Host):**
[LMStudio](https://lmstudio.ai) provides a user-friendly interface for running large language models locally.

**Configuring Moltbot to Use Mistral:**
1. **Download the Mistral model**:
   - Download the `mistral-8b` model from [LMStudio’s model hub](https://lmstudio.ai/models) and load it.
2. **Configure Moltbot to use the local model**:
   Edit `~/.moltbot/moltbot.json`:
   ```json
    {
        ...
        "models": {
            "providers": {
                "lmstudio": {
                    "baseUrl": "http://YOUR-HOST-IP:1234/v1",
                    "apiKey": "lmstudio-local",
                    "api": "openai-completions",
                    "models": [
                        {
                            "id": "mistralai/ministral-3-8b-reasoning",
                            "name": "Ministral 8B",
                            "reasoning": true,
                            "input": [
                            "text"
                            ],
                            "cost": {
                            "input": 0,
                            "output": 0,
                            "cacheRead": 0,
                            "cacheWrite": 0
                            },
                            "contextWindow": 32000, //Needed to allow your model to use the available tools from Moltbot
                            "maxTokens": 8192
                        },
                    ]
                }
            }
        },
        "agents": {
            "defaults": {
                "model": {
                    "primary": "lmstudio/mistralai/ministral-3-8b-reasoning"
                }
                ...
            }
        }
    }
   ```



---

### 3. Setting Up Browser Automation
To enable web navigation, form filling, and automation, I installed **Chromium** and configured it as a systemd service.

**Install Chromium:**
```bash
sudo snap install chromium --classic
```

**Create a Systemd Service for Persistent Chromium:**
1. Create the service file:
   ```bash
   sudo nano /etc/systemd/system/Moltbot-chromium.service
   ```
2. Paste the following configuration:
   ```ini
   [Unit]
    Description=Chromium Headless (Snap) for Clawd.bot
    After=network.target

    [Service]
    ExecStart=/snap/bin/chromium \
    --headless \
    --disable-gpu \
    --no-sandbox \
    --remote-debugging-port=9000 \
    --user-data-dir=%h/.moltbot/browser/moltbot/user-data about:blank

    Restart=on-failure
    RestartSec=5

    [Install]
    WantedBy=multi-user.target
   ```
3. Enable and start the service:
   ```bash
   sudo systemctl daemon-reload
   sudo systemctl enable moltbot-chromium.service
   sudo systemctl start moltbot-chromium.service
   ```
4. Add browser connection to your configuration, edit `~/.moltbot/moltbot.json`:
   ```json
    {
        ...
        "browser": {
            "enabled": true,
            "executablePath": "/snap/bin/chromium",
            "headless": true,
            "noSandbox": true,
            "attachOnly": false,
            "defaultProfile": "clawd",
            "controlUrl": "http://127.0.0.1:8082", //The port value depends on how you configured moltbot gateway, it's always GATEWAY_PORT + 2
            "cdpUrl": "http://127.0.0.1:9000"
        }
    }
   ```
5. Restart your moltbot gateway with `moltbot gateway restart`

**Explanation of Key Flags:**
- **`--no-sandbox`**: Required for remote debugging (Moltbot needs to control Chromium).
- **`--disable-gpu`**: Ensures consistent behavior across systems.
- **`--remote-debugging-port=9000`**: Allows Moltbot to connect and automate the browser.

---

### 4. Testing Your Setup
1. **Verify AI Model Connection:**
   ```bash
   curl http://YOUR-HOST-IP/api/v1/models
   ```
   This should return details about the Mistral model.

2. **Open your first tchat session:**
   ```bash
   moltbot tui
   ```

2. **Test Browser Automation:**
   Ask if a question to search on https://www.google.com the last trending articles about AI for January 2026.

   ![image](/img/moltbot/testBrowser.png)


---

**Security warning — run Moltbot in a sandboxed environment:** Do not give Moltbot direct access to your primary or personal accounts. Run it inside a sandbox (separate user account, container, or VM), restrict permissions to the minimum necessary, and avoid storing long-lived credentials in its configuration. Use short-lived tokens or service accounts where possible, require human approval for sensitive actions, and monitor all automated operations. AI agents can make destructive changes when unsupervised — do not let Moltbot operate alone on systems with real user accounts.

## Conclusion
By setting up Moltbot locally on my hardware, I ensured:
- **Full privacy and control** over my data and AI interactions.
- **High performance** with the Mistral 8B model for complex tasks.
- **Seamless browser automation** via Chromium for web-based workflows.
- **Persistent memory** to track progress across sessions.

This setup is ideal for users who need a **fully customizable, private, and powerful AI assistant**. Whether you're managing emails, automating tasks, or navigating the web, Moltbot provides the tools to make it happen—all while keeping your data secure and under your control.

---

### Next Steps
- Explore additional skills (e.g., GitHub integration).
- Set up multi-platform access (WhatsApp, Telegram, etc.) via Moltbot’s channel plugins.
- Customize memory retention policies to fit your workflow
 - Test allowing Moltbot to create its own pull requests: start with a local git server or a protected GitHub workflow so PRs can be reviewed before merging.
 - Experiment running Moltbot inside a macOS VM to compare interactive web navigation (full browser) versus a headless Chromium instance — evaluate compatibility, usability, and security trade-offs.
 - Create a CRON to do follow articles on my favorite website, twitter... and give me a resume. 


 




